{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c6c457-fd5c-494c-add1-54c00798f34f",
   "metadata": {},
   "source": [
    "# Unsupervised anomaly detection with Temporian and scikit-learn\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/temporian/blob/last-release/docs/src/tutorials/anomaly_detection_unsupervised.ipynb)\n",
    "\n",
    "In this tutorial, we use Temporian and Scikit-Learn to detect anomalies in a multivariate time series dataset.\n",
    "\n",
    "Anomaly detection in time series, time sequences and other temporal formats is critical in a variety of domains. For instance, it is used in manufacturing to detect equipment failure and production lines, in computer systems and by financial institutions to detect fraudulent activities, and in energy management to detect outages.\n",
    "\n",
    "We will use the Server Machine Dataset (SMD) dataset, published as part of the [OmniAnomaly](https://github.com/NetManAIOps/OmniAnomaly/) paper, which is available in CSV files in that same repository.\n",
    "\n",
    "This dataset contains aggregated resource usage metrics (e.g., CPU and RAM utilization, network traffic) from 28 computers in 3 data centers over a period of 5 weeks. The timestamps and feature names have been anonymized and normalized. Therefore, calendar feature engineering or the use of expert knowledge is not possible.\n",
    "\n",
    "The dataset will be loaded, feature engineered and converted into a tabular dataset using Temporian. Then, we will use an isolation forest model on this tabular data to detect anomalies. Finally, we will evaluate the quality of our detection on the ground truth anomalies, available as part of the testing dataset.\n",
    "\n",
    "We will first evaluate our detections both with AUC-[ROCs](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) (Area Under the Receiver operating Characteristic curve) and with [AMOCs](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2815453/) (Activity Monitoring Operating Characteristic). Unlike an ROC, an AMOC takes into account the *time to detection* or *forecasting horizon* which is often critical in temporal problems like ours. If you don't know about AMOCs yet, don't worry. We will explain it.\n",
    "\n",
    "Check out the [Supervised anomaly detection](https://temporian.readthedocs.io/en/stable/tutorials/anomaly_detection_supervised/) tutorial for a version of this notebook that trains a supervised model using the ground truth labels, which is less common in an anomaly detection setting, but can yield better performance if those are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78b58b-4d14-4306-bb45-276d1de60b11",
   "metadata": {},
   "source": [
    "## Installation and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844ff1b-224d-4e36-b7d1-dae8ed4df263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:17.239673Z",
     "iopub.status.busy": "2023-10-08T18:48:17.238841Z",
     "iopub.status.idle": "2023-10-08T18:48:19.232090Z",
     "shell.execute_reply": "2023-10-08T18:48:19.230805Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install temporian -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe822a6c-048e-4f60-b8ec-be50d724726c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:19.235679Z",
     "iopub.status.busy": "2023-10-08T18:48:19.235346Z",
     "iopub.status.idle": "2023-10-08T18:48:28.517496Z",
     "shell.execute_reply": "2023-10-08T18:48:28.516608Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import urllib.request\n",
    "\n",
    "import temporian as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796dd5b-aeb8-4ce5-820c-a1a1fb39f5b1",
   "metadata": {},
   "source": [
    "## Download dataset\n",
    "\n",
    "The dataset is made of 3 groups of 8, 9, and 11 machines respectively, with names `\"machine-1-1\"`, ..., `\"machine-3-11\"`.\n",
    "Let's list the machine names, and download records locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e591261-9c5a-4b75-acc7-1dbe850f56d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:28.520889Z",
     "iopub.status.busy": "2023-10-08T18:48:28.520552Z",
     "iopub.status.idle": "2023-10-08T18:48:28.526260Z",
     "shell.execute_reply": "2023-10-08T18:48:28.524762Z"
    }
   },
   "outputs": [],
   "source": [
    "# machines_per_group = [8, 9, 11]  # Full dataset\n",
    "machines_per_group = [3, 3, 3]  # Subset of data\n",
    "\n",
    "machines = [f\"machine-{group}-{id}\" for group, machine in zip(range(1, 4), machines_per_group) for id in range(1, machine + 1)]\n",
    "print(\"{len(machines)} machines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9edfc8c-d82b-46b2-a20e-6281383279b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:28.529768Z",
     "iopub.status.busy": "2023-10-08T18:48:28.529491Z",
     "iopub.status.idle": "2023-10-08T18:48:29.024298Z",
     "shell.execute_reply": "2023-10-08T18:48:29.023304Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"tmp/temporian_server_machine_dataset\")\n",
    "dataset_url = \"https://raw.githubusercontent.com/NetManAIOps/OmniAnomaly/master/ServerMachineDataset\"\n",
    "\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the data and labels for each machine to its own folder\n",
    "for machine in machines:\n",
    "    print(f\"Download data of {machine}\")\n",
    "\n",
    "    machine_dir = data_dir / machine\n",
    "    machine_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    data_path = machine_dir / \"data.csv\"\n",
    "    if not data_path.exists():\n",
    "        urllib.request.urlretrieve(f\"{dataset_url}/test/{machine}.txt\", data_path)\n",
    "\n",
    "    labels_path = machine_dir / \"labels.csv\"\n",
    "    if not labels_path.exists():\n",
    "         urllib.request.urlretrieve(f\"{dataset_url}/test_label/{machine}.txt\", labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44fcbc-46a6-495b-860e-c512a9603ec7",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We use Pandas to load the data into a `DataFrame` and perform tabular manipulation before importing it into a Temporian as an `EventSet`.\n",
    "\n",
    "We index the data by the `machine` column in Temporian. This was, we can apply Temporian transformations on each machine individually as well as across all machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbbdc9-5576-4fb8-9ed5-c319374d6ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:29.027942Z",
     "iopub.status.busy": "2023-10-08T18:48:29.027526Z",
     "iopub.status.idle": "2023-10-08T18:48:32.889609Z",
     "shell.execute_reply": "2023-10-08T18:48:32.888498Z"
    }
   },
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for machine in machines:\n",
    "    machine_dir = data_dir / machine\n",
    "\n",
    "    # Read the data and labels\n",
    "    print(f\"Load data of {machine}...\", end=\"\")\n",
    "    df = pd.read_csv(machine_dir / \"data.csv\", header=None).add_prefix(\"f\")\n",
    "    labels = pd.read_csv(machine_dir/ \"labels.csv\", header=None)\n",
    "    df = df.assign(label=labels)\n",
    "    df[\"machine\"] = machine\n",
    "    df[\"timestamp\"] = range(df.shape[0])\n",
    "    print(f\"found {df.shape[0]} events\")\n",
    "\n",
    "    dataframes.append(df)\n",
    "\n",
    "dataframes[0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c08eb1-4eab-4a15-b27e-084170f42e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:32.892918Z",
     "iopub.status.busy": "2023-10-08T18:48:32.892619Z",
     "iopub.status.idle": "2023-10-08T18:48:34.050805Z",
     "shell.execute_reply": "2023-10-08T18:48:34.049885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the dataframes into a single Temporian EventSet\n",
    "\n",
    "evset = tp.combine(*map(tp.from_pandas, dataframes))\n",
    "\n",
    "# Index the EventSet according the the machine name.\n",
    "evset = evset.set_index(\"machine\")\n",
    "\n",
    "# Cast the feature and label to a smaller dtypes to same one memory.\n",
    "evset = evset.cast(tp.float32).cast({\"label\": tp.int32})\n",
    "\n",
    "evset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191b2a5-3c62-4f2e-aa70-1e9eca600301",
   "metadata": {},
   "source": [
    "Awesome! Seems like each machine has more than 20.000 events and 39 features (counting the \"label\" one).\n",
    "\n",
    "As stated previously, all metrics seem to be anonymized and normalized to `[0, 1]`, so we won't need to take care of that ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649e96b-028d-4df7-b201-2c48474983c0",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "\n",
    "Let's take a look at some of the first machine's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff473e7-e477-4c92-bf27-6692f9df3059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:34.055593Z",
     "iopub.status.busy": "2023-10-08T18:48:34.055334Z",
     "iopub.status.idle": "2023-10-08T18:48:35.099611Z",
     "shell.execute_reply": "2023-10-08T18:48:35.096689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the first 3 features\n",
    "evset.plot(indexes=\"machine-1-1\", max_num_plots=3)\n",
    "\n",
    "# Plot the labels\n",
    "evset[\"label\"].plot(indexes=\"machine-1-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150c1de-c15f-426b-8e8e-5b9b73901941",
   "metadata": {},
   "source": [
    "Great! A lot to unpack here:\n",
    "- It seems to be easy to understand when an anomaly occurs (label takes value of 1) by looking at the other plots. Features 11 to 14, for example, seem to be very correlated to the label.\n",
    "- The data seems to have some periodicity to it.\n",
    "- Some features seem empty, and we could evaluate dropping them if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0275b3-bc35-4ced-8156-88c187281fdb",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "To prepare our data to train a model on it, let's start off by separating the features from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e029a7f-ef2c-46a7-b85e-5adee87ae809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:35.104618Z",
     "iopub.status.busy": "2023-10-08T18:48:35.104002Z",
     "iopub.status.idle": "2023-10-08T18:48:35.111893Z",
     "shell.execute_reply": "2023-10-08T18:48:35.110611Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = evset.schema.feature_names()\n",
    "feature_names.remove(\"label\")\n",
    "\n",
    "raw_features = evset[feature_names]\n",
    "labels = evset[\"label\"]\n",
    "\n",
    "print(\"Raw features:\", raw_features.schema)\n",
    "print(\"Labels:\", labels.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac07ee-2feb-4014-a9ea-cb52327fbe1a",
   "metadata": {},
   "source": [
    "Next, we'll need to split our dataset into train and testing sets, which we'll use an 80/20 split for.\n",
    "\n",
    "Note that the train labels will only be used for evaluation purposes.\n",
    "\n",
    "We'll be creating reusable functions for each step, since we'll do some iteration over the `feature engineering -> training -> evaluation` cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224975e6-0f5e-4ca8-8bf0-c8a2101aacfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:35.118779Z",
     "iopub.status.busy": "2023-10-08T18:48:35.118248Z",
     "iopub.status.idle": "2023-10-08T18:48:35.694528Z",
     "shell.execute_reply": "2023-10-08T18:48:35.693105Z"
    }
   },
   "outputs": [],
   "source": [
    "DROP_COLS = [\"machine\", \"timestamp\"]\n",
    "\n",
    "def split_event_set(evset: tp.EventSet, test_frac: float = 0.2):\n",
    "\n",
    "    # Average length of the records\n",
    "    average_duration = np.mean([len(machine_data.timestamps) for _, machine_data in evset.data.items()])\n",
    "    print(\"average_duration:\", average_duration)\n",
    "\n",
    "    # Select the train/test cutoff.\n",
    "    # Note: All the machines are cut at the same time. This way, we can apply pre-processing that\n",
    "    # exchange data between the machines without risk of label leakage!\n",
    "    train_cutoff = average_duration * (1 - test_frac)\n",
    "    print(\"train_cutoff:\", train_cutoff)\n",
    "\n",
    "    # Compute masks and split data based on cutoff\n",
    "    train_mask = evset.timestamps() <= int(train_cutoff)\n",
    "    test_mask = ~train_mask\n",
    "\n",
    "    # Split EventSets\n",
    "    train_evset = evset.filter(train_mask)\n",
    "    test_evset = evset.filter(test_mask)\n",
    "\n",
    "    print(f\"Train events: {train_evset.num_events()}\")\n",
    "    print(f\"Test events: {test_evset.num_events()}\")\n",
    "\n",
    "    return train_evset, test_evset\n",
    "\n",
    "def evsets_to_tabular(*evsets: tp.EventSet) -> List[np.ndarray]:\n",
    "    datasets = []\n",
    "    for evset in evsets:\n",
    "        # Fill missing values with -1 (raw data doesn't have any, but we will create some in our feature engineering)\n",
    "        df = tp.to_pandas(evset).fillna(-1)\n",
    "\n",
    "        # Remove timestamp and machine columns\n",
    "        df = df.drop(columns=DROP_COLS)\n",
    "\n",
    "        # Convert to numpy (and convert from 2D to 1D array if it has a single feature, in the case of the labels)\n",
    "        arr = df.to_numpy().squeeze()\n",
    "\n",
    "        datasets.append(arr)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "features_train, features_test = split_event_set(raw_features)\n",
    "labels_train, labels_test = split_event_set(labels)  # Note that we won't be using the train labels for training in this unsupervised setting\n",
    "\n",
    "X_train, X_test, y_train, y_test = evsets_to_tabular(features_train, features_test, labels_train, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31325157-ea11-45a3-a121-4f77ec75b7ba",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Having done all that work to prepare our data, all that remains is to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0b839-6e11-49b3-ab22-fead9408e681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:35.698803Z",
     "iopub.status.busy": "2023-10-08T18:48:35.697954Z",
     "iopub.status.idle": "2023-10-08T18:48:35.703378Z",
     "shell.execute_reply": "2023-10-08T18:48:35.702521Z"
    }
   },
   "outputs": [],
   "source": [
    "contamination = y_train.sum() / len(y_train)\n",
    "print(f\"{contamination=}\")\n",
    "\n",
    "def train(X_train):\n",
    "    model = IsolationForest(\n",
    "        contamination=contamination,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=0,\n",
    "    )\n",
    "    model.fit(X_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc17edc-4ca1-46f0-8f75-450fe284fe4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:35.705951Z",
     "iopub.status.busy": "2023-10-08T18:48:35.705724Z",
     "iopub.status.idle": "2023-10-08T18:48:43.283948Z",
     "shell.execute_reply": "2023-10-08T18:48:43.282366Z"
    }
   },
   "outputs": [],
   "source": [
    "model = train(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666cdbe-ca4f-4039-a8b4-1bf9d08226d7",
   "metadata": {},
   "source": [
    "## Evaluation using AUC-ROC\n",
    "\n",
    "We'll be reporting the model's ROC AUC score, which provides an aggregate measure of performance across all possible classification thresholds (since our model outputs an anomaly score for each sample, and in a real-world scenario it would be up to us to define the thershold from which we consider an event to be marked as anomalous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b707ff8-251d-41f9-99cb-6e0d1ab34330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:43.287325Z",
     "iopub.status.busy": "2023-10-08T18:48:43.287051Z",
     "iopub.status.idle": "2023-10-08T18:48:43.292371Z",
     "shell.execute_reply": "2023-10-08T18:48:43.291382Z"
    }
   },
   "outputs": [],
   "source": [
    "figsize=(20,3)\n",
    "\n",
    "results = {}\n",
    "\n",
    "def evaluate(model, X_test, y_test, name):\n",
    "    \"\"\"Evaluates a model on its training data and unseen test data, computing accuracy score and plotting ground truth vs predictions.\"\"\"\n",
    "    # Compute and print scores\n",
    "    roc_auc = roc_auc_score(y_test, -model.score_samples(X_test))\n",
    "\n",
    "    results[name] = {\"ROC AUC\": roc_auc}\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(pd.DataFrame(results))\n",
    "\n",
    "    # Plot predictions\n",
    "    preds = model.predict(X_test)\n",
    "    preds[preds == 1] = 0\n",
    "    preds[preds == -1] = 1\n",
    "    tp.event_set(timestamps=list(range(len(y_test))), features={\"labels\": y_test, \"predictions\": preds}).plot(style=\"vline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366162c-e72d-4d82-babd-005f6506097e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:43.295459Z",
     "iopub.status.busy": "2023-10-08T18:48:43.295205Z",
     "iopub.status.idle": "2023-10-08T18:48:47.252981Z",
     "shell.execute_reply": "2023-10-08T18:48:47.251775Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model, X_test, y_test, \"raw features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fdb2e3-3fe8-4c5a-abaa-b9693cdd2c3a",
   "metadata": {},
   "source": [
    "That's pretty decent for a first try! Our model seems to be learning.\n",
    "\n",
    "The plotted predictions seem to be all over the place though, with the model sporadically predicting anomaly events throughout in several non-anomalous periods.\n",
    "\n",
    "There's plenty of room for improvement, so let's kick off the feature engineering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b4e51-8fe7-420a-bd31-955b7b289c41",
   "metadata": {},
   "source": [
    "## Evaluation using AMOC\n",
    "\n",
    "An AMOC measure the relation between false alerts (or average time between false alerts) and the average time to detection.\n",
    "Using Temporian, it is easy to implement an AMOC.\n",
    "\n",
    "Here is how an AMOC is computed.\n",
    "\n",
    "We want to detect \"anomalies\" events. In our dataset, we generate an anomaly event each time the \"label\" (or \"target\") is true.\n",
    "Our model creates a numerical detection \"signal\". Like for an AUC, we evaluate our model with different threshold values applied on the signal.\n",
    "An \"alert\" event is generated each time the \"signal\" goes over the detection threshold.\n",
    "\n",
    "\n",
    "A \"false alert\" is an alert that does not detect an anomaly event i.e. an alert a`t` time t without any anom`aly in [t-abnomaly_win`dow, t].\n",
    "A \"missed anomaly\" is an anomaly that is not detected by any alert i.e. an anomaly `a`t time t without any a`lert in [t, t+abnomaly`_window].\n",
    "The \"time to detection\" of an anomaly` `at time t is the time between the anomaly and the first following `alert in [t, t+abnomal`y_window]. If there is not alert in this time window, the \"time to detection\" is assumed to be abnomaly_window.\n",
    "\n",
    "In practice, two anomalies that happen next to each other in time can be considered the same anomaly. So we apply a \"shutoff\" on the anomalies:\n",
    "Two anomalies cannot happen within \"missed_target_shutoff\" of each other.\n",
    "Similarly, we apply a \"shutoff\" on the false alerts.\n",
    "\n",
    "Here is a diagram to summarise\n",
    "\n",
    "![](https://raw.githubusercontent.com/google/temporian/main/docs/src/assets/amoc.svg)\n",
    "\n",
    "An AMOC can be computed on any signal, not just a model output. Let's compute the AMOC on the features `f1` and `f2`.\n",
    "We can find which one of the two features alone can best detect anomalies.he situation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cd648-245c-4d34-9f89-a98bb1d307f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:47.256506Z",
     "iopub.status.busy": "2023-10-08T18:48:47.256268Z",
     "iopub.status.idle": "2023-10-08T18:48:50.340235Z",
     "shell.execute_reply": "2023-10-08T18:48:50.339003Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@dataclass\n",
    "class ThresholdEval:\n",
    "    \"\"\"Model metric for each threshold value applied on the score.\"\"\"\n",
    "\n",
    "    threshold: float\n",
    "    num_false_alerts: int\n",
    "    num_missed_anomalies: int\n",
    "    average_time_to_detection: float\n",
    "    total_record_duration: float\n",
    "    num_machines: int\n",
    "\n",
    "def compute_detection_amoc(target : tp.EventSet,\n",
    "                   signal : tp.EventSet,\n",
    "                   detection_thresholds: List[float] = np.linspace(0,1,100, dtype=np.float32).tolist(),\n",
    "                   anomaly_window : float = 1000.,\n",
    "                   anomaly_shutoff : float = 200.,\n",
    "                   false_alert_shutoff : float = 200.,\n",
    "                   plot_first: bool = True,\n",
    "                  ) -> List[ThresholdEval]:\n",
    "    \"\"\"Computes a detection AMOC.\n",
    "\n",
    "    Args:\n",
    "        target: A boolean feature defining an anomaly to detect.\n",
    "        signal: A numerical feature detecting recent anomalies. A signal above a threshold becomes an alert.\n",
    "        detection_thresholds: List of evaluated detection thresholds applied on the \"signal\".\n",
    "        anomaly_window: For how long an anomaly can be detected.\n",
    "        anomaly_shutoff: Minimum distance between two anomalies.\n",
    "        false_alert_shutoff: Minimum distance between two missed alerts.\n",
    "        plot_first: Plot the alerts, anomalies of the first index and the mid-threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # List the anomalies\n",
    "    anomalies = target.cast(tp.bool_).filter()\n",
    "    anomalies = anomalies.filter_moving_count(anomaly_shutoff)\n",
    "\n",
    "    # Final timestamp used to collect all the metrics.\n",
    "    end_of_records = signal.end()\n",
    "    end_of_records_global = end_of_records.drop_index(keep=False).end()\n",
    "\n",
    "    def sum_by_index(evtset) -> int:\n",
    "        \"\"\"Sums of the last value of a feature in all the indexes.\"\"\"\n",
    "        assert len(evtset.schema.features) == 1 # There should be only one feature\n",
    "\n",
    "        return float(evtset.drop_index(keep=False).cumsum(sampling=end_of_records_global).get_arbitrary_index_data().features[0][0])\n",
    "\n",
    "    # The duration of record in each index is the time distance between the first and last event.\n",
    "    record_duration = signal.begin().since_last(sampling=signal.end())\n",
    "    total_record_duration = sum_by_index(record_duration)\n",
    "    print(\"total_record_duration:\",total_record_duration)\n",
    "\n",
    "    # There is one index per machine\n",
    "    num_machines = len(target.data)\n",
    "    print(\"num_machines:\",num_machines)\n",
    "\n",
    "    num_anomalies = int(anomalies.drop_index(keep=False).moving_count(np.inf, sampling=end_of_records_global).get_arbitrary_index_data().features[0][0])\n",
    "    print(\"num_anomalies:\",num_anomalies)\n",
    "\n",
    "    # Can also be computed this way:\n",
    "    assert num_anomalies == np.sum([len(machine.timestamps) for key, machine in anomalies.data.items()])\n",
    "\n",
    "    amoc = []\n",
    "\n",
    "    for threshold_idx, threshold in enumerate(detection_thresholds):\n",
    "        is_mid_threshold = threshold_idx == (len(detection_thresholds)//2)\n",
    "\n",
    "        alerts = (signal >= threshold).filter()[[]]\n",
    "\n",
    "        # False alerts\n",
    "        false_alerts = tp.equal_scalar(anomalies.moving_count(anomaly_window, sampling=alerts), 0).filter()\n",
    "        false_alerts = false_alerts.filter_moving_count(false_alert_shutoff)\n",
    "        num_false_alerts = false_alerts.moving_count(np.inf, sampling=end_of_records)\n",
    "\n",
    "        # Missed targets\n",
    "        missed_anomalies = tp.equal_scalar(alerts.moving_count(anomaly_window, sampling=anomalies.lag(anomaly_window)), 0).filter().leak(anomaly_window)\n",
    "        missed_anomalies = missed_anomalies.filter_moving_count(false_alert_shutoff)\n",
    "        num_missed_anomalies = missed_anomalies.moving_count(np.inf, sampling=end_of_records)\n",
    "\n",
    "        # Time to detection\n",
    "        time_to_detection = anomalies.until_next(sampling=alerts, timeout=anomaly_window)\n",
    "        # Set the time to detection of non detected anomalies with the maximum anomaly_window.\n",
    "        time_to_detection = tp.isnan(time_to_detection).where(anomaly_window, time_to_detection)\n",
    "        # Note: Some machines don't have alerts\n",
    "        sum_time_to_detection = time_to_detection.cumsum(sampling=end_of_records)\n",
    "\n",
    "        if plot_first and is_mid_threshold:\n",
    "            anomalies.name = \"anomalies\"\n",
    "            alerts.name = \"alerts\"\n",
    "            missed_anomalies.name = \"missed_anomalies\"\n",
    "            false_alerts.name = \"false_alerts\"\n",
    "            tp.plot([\n",
    "                target,\n",
    "                signal,\n",
    "                anomalies,\n",
    "                alerts,\n",
    "                missed_anomalies,\n",
    "                false_alerts\n",
    "                ],\n",
    "                    indexes=\"machine-1-1\",\n",
    "                   height_per_plot_px=100)\n",
    "\n",
    "        amoc.append(ThresholdEval(\n",
    "            threshold=threshold,\n",
    "            num_false_alerts=sum_by_index(num_false_alerts) / num_machines,\n",
    "            num_missed_anomalies=sum_by_index(num_missed_anomalies) / num_machines,\n",
    "            average_time_to_detection=sum_by_index(sum_time_to_detection) / num_anomalies,\n",
    "            total_record_duration=total_record_duration / num_machines,\n",
    "            num_machines=num_machines,\n",
    "        ))\n",
    "\n",
    "    return amoc\n",
    "\n",
    "def plot_detection_amoc(amoc_dict: Dict[str, List[ThresholdEval]]):\n",
    "\n",
    "    # Plot the AMOC and other related plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(5*2, 3), squeeze=False)\n",
    "\n",
    "    for name, amoc in amoc_dict.items():\n",
    "        ax = axs[0,0]\n",
    "        ax.plot([e.average_time_to_detection for e in amoc],\n",
    "                [e.num_false_alerts for e in amoc],\n",
    "               label=name)\n",
    "\n",
    "        ax = axs[0,1]\n",
    "        ax.plot([e.average_time_to_detection for e in amoc if e.num_false_alerts != 0],\n",
    "                [e.total_record_duration / e.num_false_alerts for e in amoc if e.num_false_alerts != 0],\n",
    "               label=name)\n",
    "\n",
    "    ax = axs[0,0]\n",
    "    ax.set_xlabel(\"Avg. time to detection\")\n",
    "    ax.set_ylabel(\"Num. false alerts\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axs[0,1]\n",
    "    ax.set_xlabel(\"Avg. time to detection\")\n",
    "    ax.set_ylabel(\"Avg. time between false alerts\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.invert_xaxis()\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "amoc_f1 = compute_detection_amoc(evset[\"label\"], evset[\"f1\"])\n",
    "amoc_f2 = compute_detection_amoc(evset[\"label\"], evset[\"f2\"], plot_first=False)\n",
    "\n",
    "plot_detection_amoc({\n",
    "    \"f1\":amoc_f1,\n",
    "    \"f2\":amoc_f2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d945ca5-0962-4aef-8054-12c02a953709",
   "metadata": {},
   "source": [
    "We can see that both features performs relatively equally.\n",
    "For instance, with an average time to detection of 400 time-units, both features generates approximatively ~30 false alerts for each machine.\n",
    "\n",
    "What about our detection model now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b07f3-99e3-445c-8fd2-9c9a83ebf1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:50.344817Z",
     "iopub.status.busy": "2023-10-08T18:48:50.344507Z",
     "iopub.status.idle": "2023-10-08T18:48:54.750963Z",
     "shell.execute_reply": "2023-10-08T18:48:54.749794Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_prediction_to_evtset(model):\n",
    "    df = tp.to_pandas(features_test)[[\"machine\", \"timestamp\"]]\n",
    "    df[\"detection\"] = -model.score_samples(X_test)\n",
    "    df[\"label\"] = y_test\n",
    "    evtset = tp.from_pandas(df).add_index(\"machine\")\n",
    "    return evtset\n",
    "\n",
    "pred_evtset = model_prediction_to_evtset(model)\n",
    "amoc_model_raw_features = compute_detection_amoc(pred_evtset[\"label\"], pred_evtset[\"detection\"])\n",
    "\n",
    "plot_detection_amoc({\n",
    "    \"f1\":amoc_f1,\n",
    "    \"f2\":amoc_f2,\n",
    "    \"model:raw features\": amoc_model_raw_features,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3b0d3a-34be-4bbd-aa9e-65b10f7ee11c",
   "metadata": {},
   "source": [
    "The model is **much** better than the features alone. This is expected, but it is a good check to do :)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7cbd3-4de1-40ba-ae39-ba8bd896d741",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "### Lag features\n",
    "\n",
    "Right now our model only has access to each event's raw metric values, + the group and machine that it belongs to. This means that it has no knowledge of the **context** an event is happening on - some values might have been completely normal when the measuring started, but anomalous a couple of weeks later, e.g. if that machine's usage went up as a whole during that time and its baseline usage now stands much higher than it used to.\n",
    "\n",
    "To combat this, we'll start by lagging the values of each feature. In doing this, we're providing the model (some) information about that the metric's value looked like a couple of steps into the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd6eb6-cccc-4586-86a5-c6971d6a86c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:54.756461Z",
     "iopub.status.busy": "2023-10-08T18:48:54.756129Z",
     "iopub.status.idle": "2023-10-08T18:48:55.758005Z",
     "shell.execute_reply": "2023-10-08T18:48:55.757104Z"
    }
   },
   "outputs": [],
   "source": [
    "lag_features = []\n",
    "\n",
    "# Lag each raw feature by 1, 2, ..., 10 steps\n",
    "for window in range(1, 11):\n",
    "    lag_features.append(raw_features.lag(window).resample(raw_features).prefix(f\"lag_{window}_\"))\n",
    "\n",
    "features = tp.glue(raw_features, *lag_features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ad111-1a24-4702-8683-7ac84c46be07",
   "metadata": {},
   "source": [
    "Let's take a look at any metric alongside its lagged values. We'll select a small time window, to be able to appreciate how the time series moves to the right as the number of lagged timesteps increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1db9a2-eb34-417a-ae8b-a99a790c95a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:55.763733Z",
     "iopub.status.busy": "2023-10-08T18:48:55.763468Z",
     "iopub.status.idle": "2023-10-08T18:48:56.360707Z",
     "shell.execute_reply": "2023-10-08T18:48:56.360050Z"
    }
   },
   "outputs": [],
   "source": [
    "f13_lags = features[[\"f13\"] + [f\"lag_{i}_f13\" for i in range(1, 11)]]\n",
    "timestamps = f13_lags.timestamps()\n",
    "f13_lags = f13_lags.filter((timestamps > 21500) & (timestamps < 21600))\n",
    "f13_lags.plot(max_num_plots=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47607936-3371-4c89-803c-f9f68d74bbe6",
   "metadata": {},
   "source": [
    "Time to train and evaluate a new model with these new features! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429abf92-249b-410b-bd76-5eb8a7a23c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:48:56.369229Z",
     "iopub.status.busy": "2023-10-08T18:48:56.368476Z",
     "iopub.status.idle": "2023-10-08T18:49:30.497730Z",
     "shell.execute_reply": "2023-10-08T18:49:30.496567Z"
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test = split_event_set(features)\n",
    "_, labels_test = split_event_set(labels)\n",
    "\n",
    "X_train, X_test, y_test = evsets_to_tabular(features_train, features_test, labels_test)\n",
    "\n",
    "model = train(X_train)\n",
    "evaluate(model, X_test, y_test, \"lagged features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f42e3a-1c76-4654-a4e0-7890c640c2fc",
   "metadata": {},
   "source": [
    "Nice! The lagged features seem to have helped the model quite a bit. The ROC AUC went up, and the predictions are already looking more solid, with several anomalous periods being correctly identified.\n",
    "\n",
    "What about the AMOC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddc381-4188-4d8c-8fc4-f4ef84c1ed7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:49:30.501122Z",
     "iopub.status.busy": "2023-10-08T18:49:30.500848Z",
     "iopub.status.idle": "2023-10-08T18:49:37.262428Z",
     "shell.execute_reply": "2023-10-08T18:49:37.261172Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_evtset = model_prediction_to_evtset(model)\n",
    "amoc_model_lagged_features = compute_detection_amoc(pred_evtset[\"label\"], pred_evtset[\"detection\"])\n",
    "\n",
    "plot_detection_amoc({\n",
    "    \"model:raw features\": amoc_model_raw_features,\n",
    "    \"model:lagged features\": amoc_model_lagged_features,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63da664-9184-4d57-93db-669d49bcfe50",
   "metadata": {},
   "source": [
    "**TODO:** The model with raw features is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b6fcb4-6aa6-484f-9876-edfa31c1f54f",
   "metadata": {},
   "source": [
    "### Moving statistic features\n",
    "\n",
    "Although useful, the raw lagged values aren't enough to provide the model a comprehensive look at each value's past context. Note also that we only gave it a glimpse of 10 steps into the past, and each time series has more than 23k values.\n",
    "\n",
    "This is where **moving statistics** can come in handy. Instead of a list of raw values, we can provide the model an aggregation of each metric's values over the last N timesteps. For example, we can tell it what the maximum and minimum value of a metric were in the last 20 steps, or what the standard deviation was in the last 1000. \n",
    "\n",
    "Luckily, Temporian's window operators make this a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b4702-6818-4801-ab3b-f1c97443bbc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:49:37.267197Z",
     "iopub.status.busy": "2023-10-08T18:49:37.266942Z",
     "iopub.status.idle": "2023-10-08T18:50:10.479369Z",
     "shell.execute_reply": "2023-10-08T18:50:10.478199Z"
    }
   },
   "outputs": [],
   "source": [
    "moving_statistic_features = []\n",
    "\n",
    "# Compute the moving average, standard deviation, max, and min over different windows\n",
    "for window in [20, 200, 2000]:\n",
    "    moving_statistic_features.append(raw_features.simple_moving_average(window).prefix(f\"avg_{window}_\"))\n",
    "    moving_statistic_features.append(raw_features.moving_standard_deviation(window).prefix(f\"std_{window}_\"))\n",
    "    moving_statistic_features.append(raw_features.moving_max(window).prefix(f\"max_{window}_\"))\n",
    "    moving_statistic_features.append(raw_features.moving_min(window).prefix(f\"min_{window}_\"))\n",
    "\n",
    "features = tp.glue(raw_features, *lag_features, *moving_statistic_features)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdf189-cd8a-4bf0-ad9b-dbcdf1f89e3a",
   "metadata": {},
   "source": [
    "Taking a look at some of the generated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630aa0b4-745d-49f1-9cb8-de5f36f1fd96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:50:10.485592Z",
     "iopub.status.busy": "2023-10-08T18:50:10.484787Z",
     "iopub.status.idle": "2023-10-08T18:50:11.180765Z",
     "shell.execute_reply": "2023-10-08T18:50:11.179741Z"
    }
   },
   "outputs": [],
   "source": [
    "f13_stats = features[[\"f13\", \"avg_20_f13\", \"avg_200_f13\", \"max_20_f13\", \"max_200_f13\"]]\n",
    "timestamps = f13_stats.timestamps()\n",
    "f13_stats = f13_stats.filter((timestamps > 21000) & (timestamps < 21100))\n",
    "f13_stats.plot(indexes=\"machine-1-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a758f6-de8b-40d7-adaa-8a55b37a0974",
   "metadata": {},
   "source": [
    "Moving statistics can be a good indicator of what a sequence's \"normal\" behavior looks like. \n",
    "\n",
    "As an example, `\"avg_20_f12\"`'s plot shows how the average value of the series goes up with time - so it could allow the model to tell apart whether a value of `0.07` for `f13` is anomalous or not, depending on when it happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937dac2-b6cf-43ab-8470-900e42932c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:50:11.187566Z",
     "iopub.status.busy": "2023-10-08T18:50:11.187311Z",
     "iopub.status.idle": "2023-10-08T18:51:10.132262Z",
     "shell.execute_reply": "2023-10-08T18:51:10.130892Z"
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test = split_event_set(features)\n",
    "_, labels_test = split_event_set(labels)\n",
    "\n",
    "X_train, X_test, y_test = evsets_to_tabular(features_train, features_test, labels_test)\n",
    "\n",
    "model = train(X_train)\n",
    "evaluate(model, X_test, y_test, \"moving statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d425a0-9714-4c54-a9e3-ee283287091c",
   "metadata": {},
   "source": [
    "That's quite an improvement! Moving statistics can be of inmense importance in an anomaly detection setting, since \"anomalous\" values tend to be defined as those that don't match the item's normal behavior, and moving statistics can help the model understand what \"normal behavior\" means for a a specific timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee321b-57cb-42dd-99fa-c9891a1f0017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-08T18:51:10.135605Z",
     "iopub.status.busy": "2023-10-08T18:51:10.135342Z",
     "iopub.status.idle": "2023-10-08T18:51:21.025588Z",
     "shell.execute_reply": "2023-10-08T18:51:21.024342Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_evtset = model_prediction_to_evtset(model)\n",
    "amoc_model_moving_statistics = compute_detection_amoc(pred_evtset[\"label\"], pred_evtset[\"detection\"])\n",
    "\n",
    "plot_detection_amoc({\n",
    "    \"model:raw features\": amoc_model_raw_features,\n",
    "    \"model:lagged features\": amoc_model_lagged_features,\n",
    "    \"model:moving statistics\": amoc_model_moving_statistics,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb848f88-98c8-436b-a379-81ff377142a9",
   "metadata": {},
   "source": [
    "**TODO:** The model with moving statsitics is event worst."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17562ccf-ce6c-4185-9d3c-2b4bf274aed0",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "In this notebook we learned how to perform feature engineering and visualization using Temporian, applying it to a real-world anomaly detection use case.\n",
    "\n",
    "There's some further work that could be done in this problem! Here's some ideas:\n",
    "- Train a larger model! Training a larger model, on a larger dataset, would most likely yield improved results. As an example, try increasing the number of estimators in the IsolationForest (the default is 100), and optionally also increase the number of machines in each group to pull data from, and re-run the experiments!\n",
    "- Use the dataset's [unlabeled train data](https://github.com/NetManAIOps/OmniAnomaly/tree/master/ServerMachineDataset/train) to train the model in this unsupervised manner, and then use the data we used here to test it only.\n",
    "- Keep adding new features! As we demonstrated, a very simple model can go a long way if the correct features are provided to it. This is where Temporian shines - check out the full list of operators in the [API Reference](https://temporian.readthedocs.io/en/stable/reference/#operators) for some inspiration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
