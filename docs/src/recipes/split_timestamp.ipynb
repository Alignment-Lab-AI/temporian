{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d71ce2-2e81-45ef-a494-0a07a03554bc",
   "metadata": {},
   "source": [
    "# Split data at a given timestamp\n",
    "\n",
    "This recipe can be used to split an `EventSet` in two or more subsets at fixed timestamps.\n",
    "\n",
    "This exact same procedure applies to multi-index data or the default single empty index.\n",
    "\n",
    "For example, to train a machine learning forecasting model, the data usually needs to be split into train, validation and test `EventSets` at some fixed timestamps in that respective order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cd99f-6c1e-4655-8bfe-767e547d6014",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "In this toy example we'll use two separate indexes, but this also applies to any number of indexes as mentioned above.\n",
    "\n",
    "The second index has 2 more data points from the previous year. Both of them finish at the same date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abb293-e542-4540-9c65-3cf1c89c4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import temporian as tp\n",
    "\n",
    "sample_data = pd.DataFrame(\n",
    "    data=[\n",
    "        # date,  index=1, feature\n",
    "        [\"2020-01-01\", 1, 1.0],\n",
    "        [\"2020-02-01\", 1, 2.0],\n",
    "        [\"2020-03-01\", 1, 3.0],\n",
    "        [\"2020-04-01\", 1, 4.0],\n",
    "        [\"2020-05-01\", 1, 5.0],\n",
    "        [\"2020-06-01\", 1, 6.0],\n",
    "        # date,  index=2, feature\n",
    "        [\"2019-11-01\", 2, -20.0],\n",
    "        [\"2019-12-01\", 2, -10.0],\n",
    "        [\"2020-01-01\", 2, 10.0],\n",
    "        [\"2020-02-01\", 2, 20.0],\n",
    "        [\"2020-03-01\", 2, 30.0],\n",
    "        [\"2020-04-01\", 2, 40.0],\n",
    "        [\"2020-05-01\", 2, 50.0],\n",
    "        [\"2020-06-01\", 2, 60.0],\n",
    "    ],\n",
    "    columns=[\n",
    "        \"timestamp\",\n",
    "        \"idx\",\n",
    "        \"feature\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "sample_evset = tp.from_pandas(sample_data, indexes=[\"idx\"])\n",
    "sample_evset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cc1b4-ac53-4f41-ad59-9f98fa0f0210",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "We want to split this into 3 separate `EventSets` as follows:\n",
    "* **Train** data: all data points until `2020-03-01` (including it)\n",
    "* **Validation**: after training and until `2020-05-01` (including it)\n",
    "* **Test**: data after `2020-05-01` (not including it)\n",
    "\n",
    "So the proposed steps are:\n",
    "1. Convert the timestamps of events into a feature.\n",
    "2. Filter train/validation/test by comparing the timestamps feature to the defined boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e85cea-9814-40cc-8ffd-dfc87a5e8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define boundaries for train/validation/test\n",
    "train_until = datetime(2020, 3, 1).timestamp()\n",
    "val_until = datetime(2020, 5, 1).timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e540ec-3b8b-4ba0-a727-23c71ca56cd0",
   "metadata": {},
   "source": [
    "### 1. Convert the timestamps into a feature\n",
    "\n",
    "The `timestamps()` operator creates a single-feature `EventSet` with the unix timestamp of each event, keeping the indexes and samplings compatible with the original `EventSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92545fdc-ee14-4ea3-aa85-02b6ef252a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data timestamps as a feature\n",
    "sample_timestamps = sample_evset.timestamps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d52487-3006-4bf9-9c4c-dad3d47db300",
   "metadata": {},
   "source": [
    "### 2. Split based on timestamps\n",
    "\n",
    "Now we compare the timestamps feature to the boundary timestamps of each subset. This will create boolean `EventSets` that can be passed directly to the `filter()` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1afd17-ccfa-4bd8-b0bf-406fa098aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evset = sample_evset.filter(sample_timestamps <= train_until)\n",
    "val_evset = sample_evset.filter((sample_timestamps > train_until) & (sample_timestamps <= val_until))\n",
    "test_evset = sample_evset.filter(sample_timestamps > val_until)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09775af5-c18e-4edf-b7dd-038772a63f50",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af0fc5-9fe4-48b2-80c3-587dec522bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26cf689-cf12-40de-93b9-c0b13e0b27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_evset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e85b3-f318-4669-8b23-1441b3182ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349e115-f4f8-4ada-82c7-dbd0ee695e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
