{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74f7111-1b6c-4454-9770-3f67eeadaca6",
   "metadata": {},
   "source": [
    "# Aggregate events at a fixed interval\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/temporian/blob/last-release/docs/src/recipes/aggregate_interval.ipynb)\n",
    "\n",
    "This recipe aggregates possibly non-uniformly sampled events into fixed-length intervals (e.g., seconds, hours, days, or weeks). In other words, it converts the event features into time series.\n",
    "\n",
    "For example, suppose we have the sales log from a store, where each sold item is represented by an event. Let's assume each sale event has a date-time, the sale price and the unit cost of the product. We want to calculate total daily sales, with one single event at `00:00` each day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de274e0e-ab5a-46a0-b4b9-f1026b43076c",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "Let's create some sale events with **non-uniform sampling** and the mentioned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a56d43-d011-4e72-aed4-8d460d58c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import temporian as tp\n",
    "\n",
    "sales_data = pd.DataFrame(\n",
    "    data=[\n",
    "        # sale timestamp,   price, cost\n",
    "        [\"2020-01-01 13:04\", 3.0,  1.0],\n",
    "        [\"2020-01-01 13:04\", 5.0,  2.0],  # duplicated timestamp\n",
    "        [\"2020-01-02 15:24\", 7.0,  3.0],\n",
    "        [\"2020-01-03 13:45\", 3.0,  1.0],\n",
    "        [\"2020-01-03 16:10\", 7.0,  3.0],\n",
    "        [\"2020-01-03 17:30\", 10.0, 5.0],\n",
    "        [\"2020-01-06 10:10\", 4.0,  2.0],\n",
    "        [\"2020-01-06 19:35\", 3.0,  1.0],\n",
    "    ],\n",
    "    columns=[\n",
    "        \"timestamp\",\n",
    "        \"unit_price\",\n",
    "        \"unit_cost\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "sales_evset = tp.from_pandas(sales_data)\n",
    "sales_evset.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6189a-ca80-4869-b8a6-35356ce42c02",
   "metadata": {},
   "source": [
    "## Solution\n",
    "We want to calculate total daily sales. So this is what we can do:\n",
    "1. Create a uniform sampling with one tick per day (could be any other interval), at time `00:00:00`.\n",
    "1. Add up all sales that happened between `00:00:01` from the previous day, and the current tick at `00:00:00`.\n",
    "\n",
    "### 1. Create uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e930b36-10f6-487f-8466-278a1a08956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time span to cover: one week\n",
    "time_span = tp.event_set(timestamps=[\"2020-01-01 00:00\", \"2020-01-07 00:00\"])\n",
    "\n",
    "# Create daily ticks at 00:00\n",
    "interval = tp.duration.days(1)\n",
    "ticks = time_span.tick(interval)\n",
    "\n",
    "ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad79b2d-3fea-4e11-8d68-1e5d78f3b655",
   "metadata": {},
   "source": [
    "### 2. Aggregate the events\n",
    "\n",
    "Now we can aggregate the events between ticks, in this case by running a moving sum over the specified `sampling=ticks`, with the `window_length` equal to the interval between ticks.\n",
    "\n",
    "Note that all moving window operators support the `sampling` argument, so any other kind of aggregation could be used depending on the use case (e.g: moving average, max, min)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92dff9-b4b6-42d1-8848-b37ff768ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide uniform ticks as sampling\n",
    "moving_sum = sales_evset.moving_sum(window_length=interval, sampling=ticks)\n",
    "\n",
    "moving_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f50a9-72ab-4673-aa38-8c3dacdcf49d",
   "metadata": {},
   "source": [
    "## (Optional) Rename and plot\n",
    "\n",
    "Finally, we can rename features to match their actual meaning after aggregation.\n",
    "\n",
    "In this case we also calculate and plot the daily profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664550bb-12ac-43c2-8216-4308843178b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename aggregated features\n",
    "daily_sales = moving_sum.rename({\"unit_price\": \"daily_revenue\", \"unit_cost\": \"daily_cost\"})\n",
    "\n",
    "# Profit = revenue - cost\n",
    "daily_profit = (daily_sales[\"daily_revenue\"] - daily_sales[\"daily_cost\"]).rename(\"daily_profit\")\n",
    "\n",
    "daily_profit.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a9c6e6-5cba-4950-900f-1878e87a98be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
